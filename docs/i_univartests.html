<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistics - 3&nbsp; Univariate Hypothesis Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./i_bivariate.html" rel="next">
<link href="./i_distributions.html" rel="prev">
<link href="./images/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Univariate Hypothesis Testing</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Statistics and Data</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./i_univariate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Univariate Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./i_distributions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Univariate Distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./i_univartests.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Univariate Hypothesis Testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./i_bivariate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bivariate Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./i_bivartests.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regression Hypothesis Testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./i_references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#null-hypothesis-significance-testing" id="toc-null-hypothesis-significance-testing" class="nav-link active" data-scroll-target="#null-hypothesis-significance-testing"><span class="toc-section-number">3.1</span>  Null Hypothesis Significance Testing</a>
  <ul class="collapse">
  <li><a href="#the-process-of-null-hypothesis-significance-testing" id="toc-the-process-of-null-hypothesis-significance-testing" class="nav-link" data-scroll-target="#the-process-of-null-hypothesis-significance-testing"><span class="toc-section-number">3.1.1</span>  The Process of Null Hypothesis Significance Testing</a></li>
  </ul></li>
  <li><a href="#parametric-tests-for-comparing-means" id="toc-parametric-tests-for-comparing-means" class="nav-link" data-scroll-target="#parametric-tests-for-comparing-means"><span class="toc-section-number">3.2</span>  Parametric Tests for Comparing Means</a>
  <ul class="collapse">
  <li><a href="#one-sample-test" id="toc-one-sample-test" class="nav-link" data-scroll-target="#one-sample-test"><span class="toc-section-number">3.2.1</span>  One-Sample Test</a></li>
  <li><a href="#two-sample-tests" id="toc-two-sample-tests" class="nav-link" data-scroll-target="#two-sample-tests"><span class="toc-section-number">3.2.2</span>  Two-Sample Tests</a></li>
  </ul></li>
  <li><a href="#z-tests" id="toc-z-tests" class="nav-link" data-scroll-target="#z-tests"><span class="toc-section-number">3.3</span>  z-tests</a>
  <ul class="collapse">
  <li><a href="#one-sample-test-1" id="toc-one-sample-test-1" class="nav-link" data-scroll-target="#one-sample-test-1"><span class="toc-section-number">3.3.1</span>  One-Sample Test</a></li>
  <li><a href="#paired-samples-test" id="toc-paired-samples-test" class="nav-link" data-scroll-target="#paired-samples-test"><span class="toc-section-number">3.3.2</span>  Paired-Samples Test</a></li>
  <li><a href="#independent-samples-test" id="toc-independent-samples-test" class="nav-link" data-scroll-target="#independent-samples-test"><span class="toc-section-number">3.3.3</span>  Independent-Samples Test</a></li>
  </ul></li>
  <li><a href="#t-tests" id="toc-t-tests" class="nav-link" data-scroll-target="#t-tests"><span class="toc-section-number">3.4</span>  t-tests</a>
  <ul class="collapse">
  <li><a href="#one-sample-test-2" id="toc-one-sample-test-2" class="nav-link" data-scroll-target="#one-sample-test-2"><span class="toc-section-number">3.4.1</span>  One-Sample Test</a></li>
  <li><a href="#paired-samples-test-1" id="toc-paired-samples-test-1" class="nav-link" data-scroll-target="#paired-samples-test-1"><span class="toc-section-number">3.4.2</span>  Paired-Samples Test</a></li>
  <li><a href="#independent-samples-test-1" id="toc-independent-samples-test-1" class="nav-link" data-scroll-target="#independent-samples-test-1"><span class="toc-section-number">3.4.3</span>  Independent-Samples Test</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Univariate Hypothesis Testing</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="null-hypothesis-significance-testing" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="null-hypothesis-significance-testing"><span class="header-section-number">3.1</span> Null Hypothesis Significance Testing</h2>
<p>The central dogma of statistics is to make estimates about the population based on samples. Null Hypothesis Significance Testing (NHST) is a widely used statistical approach for testing the validity of a claim or hypothesis about a population based on sample data. The process involves comparing the observed data to what would be expected under a null hypothesis, which usually assumes no effect or relationship between variables.</p>
<p><strong>Null Hypothesis</strong></p>
<p>The null hypothesis (denoted as <span class="math inline">\(H_0\)</span>) is usually a statement of no effect or no difference. It represents the default assumption that there is no relationship between the variables under investigation or that the treatment has no effect.</p>
<p><strong>Alternative Hypothesis</strong></p>
<p>The alternative hypothesis (denoted as <span class="math inline">\(H_a\)</span>) is a statement that contradicts the null hypothesis. It represents the claim that there is a relationship between the variables or that the treatment has an effect. The alternative hypothesis is what researchers hope to provide evidence for through the process of hypothesis testing.</p>
<section id="the-process-of-null-hypothesis-significance-testing" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="the-process-of-null-hypothesis-significance-testing"><span class="header-section-number">3.1.1</span> The Process of Null Hypothesis Significance Testing</h3>
<ol type="1">
<li><p>State the <strong>null hypothesis</strong> (<span class="math inline">\(H_0\)</span>) and <strong>alternative hypothesis</strong> (<span class="math inline">\(H_a\)</span>). The null hypothesis is a statement of no effect or relationship between the variables being tested, while the alternative hypothesis is a statement that claims some effect or relationship between the variables.</p></li>
<li><p>Choose a <strong>significance level</strong>. The significance level, denoted by <span class="math inline">\(\alpha\)</span>, is the probability of rejecting the null hypothesis when it is true. The most commonly used significance level is 0.05</p></li>
<li><p>Collect data and calculate the <strong>test statistic</strong>. Gather your sample data and perform the appropriate statistical test to calculate the test statistic. The test statistic is a numerical value that measures the difference between the observed data and what would be expected under the null hypothesis. Different tests use different test statistics meaning each one is denoted differently dependent on which test. Common test statistics include <span class="math inline">\(z\)</span>, <span class="math inline">\(t\)</span>, <span class="math inline">\(F\)</span>, or <span class="math inline">\(\chi^2\)</span>.</p></li>
<li><p>Determine the <strong>p-value</strong>. The p-value, denoted as <span class="math inline">\(p\)</span>, is the probability of observing a test statistic as extreme or more extreme than the one calculated from the sample data, assuming the null hypothesis is true. It quantifies the evidence against the null hypothesis. Lower p-values indicate stronger evidence against the null hypothesis since they imply that the observed results are less likely to have occurred by chance alone under the null hypothesis. In other words, a smaller p-value suggests that the observed effect or relationship between the variables is more likely to be genuine and not just a random occurrence. Conversely, higher p-values indicate weaker evidence against the null hypothesis. This means that the observed results are more likely to have occurred by chance under the null hypothesis, and there is insufficient evidence to suggest that the effect or relationship is genuine.</p></li>
<li><p>Compare the p-value to the significance level (<span class="math inline">\(\alpha\)</span>). If the p-value is less than or equal to the chosen significance level (<span class="math inline">\(p \leq α\)</span>), then reject the null hypothesis in favor of the alternative hypothesis. This implies that there is statistically significant evidence to support the claim made by the alternative hypothesis. If the p-value is greater than the significance level (<span class="math inline">\(p &gt; α\)</span>), then do not reject the null hypothesis, as there is not enough evidence to support the alternative hypothesis</p></li>
<li><p>Interpret the results and draw conclusions. Based on the comparison between the p-value and the significance level, make a conclusion about the null hypothesis. If you rejected the null hypothesis, this suggests the alternative hypothesis is supported by the data. If you failed to reject the null hypothesis, this means there is insufficient evidence to support the alternative hypothesis. Keep in mind that failing to reject the null hypothesis does not prove it is true; it simply means that the data does not provide strong evidence against it.</p></li>
</ol>
<p>It is crucial to note that failing to reject the null hypothesis does not prove it is true; rather, it indicates that there is not enough evidence to conclude that the alternative hypothesis is true. Additionally, the p-value is subject to various limitations and potential misinterpretations, so it is essential to consider effect sizes, confidence intervals, and other aspects of the data when making conclusions from hypothesis testing.</p>
</section>
</section>
<section id="parametric-tests-for-comparing-means" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="parametric-tests-for-comparing-means"><span class="header-section-number">3.2</span> Parametric Tests for Comparing Means</h2>
<p>Parametric tests are statistical procedures that make specific assumptions about the parameters or the distribution of the populations from which the data is drawn. They are powerful and can provide more reliable results when the assumptions are met. The most common type of parametric test involves the comparison of means.</p>
<section id="one-sample-test" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="one-sample-test"><span class="header-section-number">3.2.1</span> One-Sample Test</h3>
<p>A <strong>one-sample test</strong> is used when you have raw data and a population mean. This kind of test aims to determine whether there is a statistically significant difference between the mean of the sample and the known population mean. One-sample tests are particularly useful when you want to test a specific hypothesis about a population mean.</p>
<ul>
<li><strong>Example Usage</strong>: A researcher wants to determine if the average height of a specific type of tree in a national park differs from the known average height of that type of tree worldwide.</li>
</ul>
</section>
<section id="two-sample-tests" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="two-sample-tests"><span class="header-section-number">3.2.2</span> Two-Sample Tests</h3>
<p>Two-sample tests are utilized when we are interested in comparing the difference of means or the mean of the differences of two different groups or samples.</p>
<p><strong>Paired Samples Test</strong></p>
<p>A <strong>paired samples test</strong>, also known as a dependent samples test or paired test, is used when you have two related samples or pairs of samples. This test is commonly used in ‘before-and-after’ scenarios where the same group is tested twice, under different conditions. The paired samples test assesses if the means of these two samples significantly differ by comparing the <strong>mean of the differences</strong>.</p>
<ul>
<li><strong>Example Usage</strong>: A researcher wants to assess the effect of a new teaching method on students’ performance by comparing test scores before and after the implementation of the new method.</li>
</ul>
<p><strong>Independent Samples Test</strong></p>
<p>An <strong>independent samples test</strong>, also known as two sample test, is used when you have two independent samples and aim to compare their means. The samples are independent in the sense that the selection of individuals in one group does not influence the selection of individuals in the other group. This test investigates if the means of these two independent samples significantly differ by comparing the <strong>difference of the means</strong>.</p>
<ul>
<li><strong>Example Usage</strong>: A researcher wants to compare the average heights of two different species of trees to determine if one species tends to be taller than the other.</li>
</ul>
</section>
</section>
<section id="z-tests" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="z-tests"><span class="header-section-number">3.3</span> z-tests</h2>
<section id="one-sample-test-1" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="one-sample-test-1"><span class="header-section-number">3.3.1</span> One-Sample Test</h3>
<p>A one-sample z-test is used to compare the mean of a sample to a specified value. It is a parametric test that assumes the population is normally distributed and the <strong>population standard deviation is known</strong>. The test statistic for a one-sample z-test is the z-score, which is calculated using the sample mean, the population mean, and the population standard deviation.</p>
<p><span class="math display">\[
\sigma = \text{known population standard deviation}
\]</span></p>
<p><strong>Set of Hypotheses:</strong> For a one-sample z-test, the null hypothesis (<span class="math inline">\(H_0\)</span>) is that the population mean (<span class="math inline">\(\mu\)</span>) is equal to a specified value (<span class="math inline">\(\mu_0\)</span>). The alternative hypothesis (<span class="math inline">\(H_a\)</span>) is that the population mean (<span class="math inline">\(\mu\)</span>) is not equal to the specified value (<span class="math inline">\(\mu_0\)</span>).</p>
<p><span class="math display">\[
\begin{align*}
H_0: \mu = \mu_0\\ \;\;\;\;\;
H_a: \mu \neq \mu_0
\end{align*}
\]</span></p>
<p><strong>Significance Level:</strong></p>
<p>The significance level (<span class="math inline">\(\alpha\)</span>) is the probability of rejecting the null hypothesis when it is true. We will use the most commonly used significance level, 0.05.</p>
<p><span class="math display">\[
\alpha = 0.05
\]</span></p>
<p><strong>Making the Sampling Distribution</strong></p>
<p>Imagine we took a million samples of the population. Each sample would have a slightly different sample mean. This is called a sampling distribution. This is useful since we can use the sampling distribution to calculate the probability of obtaining a sample mean as extreme or more extreme than what we would expect. Since sampling a population a million times is not feasible, we can use the <strong>Central Limit Theorem</strong> to create a sampling distribution of the mean. The Central Limit Theorem states that the sampling distribution of the mean will be normally distributed with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size. Thus the standard deviation of the sampling distribution of <span class="math inline">\(\bar{X}\)</span> would be equal to <span class="math inline">\(\sigma_{\bar{X}}\)</span></p>
<p><span class="math display">\[
\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>Under the null hypothesis, the sampling distribution of the mean would be centered at <span class="math inline">\(\mu_0\)</span>, rather than the actual population mean, <span class="math inline">\(\mu\)</span>. We do this because we are assuming that the null hypothesis is true. This is useful because we can see if it is probable that our sample would have come from a population with a mean equal to <span class="math inline">\(\mu_0\)</span>- meaning if our sample mean is significantly different from <span class="math inline">\(\mu_0\)</span>, we have found something interesting.</p>
<p>To clarify, this <strong>null distribution</strong> is what the distribution of test statistics would look like if the null hypothesis were true. The null distribution is a normal distribution with a mean equal to <span class="math inline">\(\mu_0\)</span> and a standard deviation equal to <span class="math inline">\(\sigma_{\bar{X}}\)</span>.</p>
<p><em>Below is a visualization of the hypothesized null distribution</em></p>
<p><img src="images/mu0s.png" class="img-fluid"></p>
<p><strong>Our Sample</strong></p>
<p>The sample mean (<span class="math inline">\(\bar{X}\)</span>) is the average of all the values (<span class="math inline">\(X_i\)</span>’s’) in the sample that we collected. It is calculated by summing up all the values in the sample and dividing by the sample size (<span class="math inline">\(n\)</span>).</p>
<p><span class="math display">\[
\bar{X} = \frac{\sum_{i=1}^{n}{X_i}}{n}
\]</span></p>
<p><em>Our Sample’s Test-Statistic:</em></p>
<p>We have just caluclated the sample mean, <span class="math inline">\(\bar{X}\)</span>. We hypothesized that the population mean is equal to a specified value, <span class="math inline">\(\mu_0\)</span>. We want to know if the sample mean is significantly different from the population mean. We can calculate our test-statistic, the z-score, to find out where on the sampling distribution our sample mean lies. The z-score is calculated using the sample mean, the population mean, and the population standard deviation.</p>
<p><span class="math display">\[
z = \frac{\bar{X} - \mu_0}{\sigma_{\bar{X}}}
\]</span></p>
<p><strong>Calculating the p-value</strong> In the context of a z-test, we use a standard normal distribution to derive a p-value. We begin by standardizing our test statistic (the sample mean) to a z-score using the population mean and standard deviation. This z-score can then be used to find the p-value of our test.</p>
<p>Let <span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span> be a standard normal random variable and <span class="math inline">\(z\)</span> be the observed z-score.</p>
<p>Given this observed z-score, we can then compute the p-value, which is the probability of observing a z-score as extreme as <span class="math inline">\(z\)</span> under the null hypothesis.</p>
<ul>
<li><p>For a two-tailed z-test (where we’re testing for a difference in either direction): When <span class="math inline">\(H_a: \mu \neq \mu_0\)</span>, then <span class="math inline">\(p = 2 \times (1 - \text{Pr}(Z \leq |z|))\)</span></p></li>
<li><p>For a right-tailed z-test (where we’re testing for a difference in the positive direction): When <span class="math inline">\(H_a: \mu &gt; \mu_0\)</span>, then <span class="math inline">\(p = 1 - \text{Pr}(Z \leq z)\)</span></p></li>
<li><p>For a left-tailed z-test (where we’re testing for a difference in the negative direction): When <span class="math inline">\(H_a: \mu &lt; \mu_0\)</span>, then <span class="math inline">\(p = \text{Pr}(Z \leq z)\)</span></p></li>
</ul>
<p><em>Applet to calculate the p-value</em></p>
<center>
<div width="90%">
<iframe src="https://byuimath.com/apps/normprob.html?width=600&amp;z=1&amp;height=400&amp;left=1&amp;mid=0&amp;right=1&amp;area=a&amp;static=0&amp;title=1&amp;border=0" frameborder="0" width="650" height="450" data-external="1"></iframe>
</div>
</center>
</section>
<section id="paired-samples-test" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="paired-samples-test"><span class="header-section-number">3.3.2</span> Paired-Samples Test</h3>
<p>A paired-samples z-test, also known as a dependent sample z-test, is used to compare the mean differences of two related groups to assess whether the mean difference between paired observations in the population is significantly different from a number (usually zero). This test assumes the differences between pairs are normally distributed and the <strong>population standard deviation of the differences is known</strong>. The test statistic for a paired-samples z-test is the z-score, which is calculated using the sample mean difference, the population mean difference, and the population standard deviation of the differences.</p>
<p><span class="math display">\[
\sigma_d = \text{known population standard deviation of differences}
\]</span></p>
<p>Additionally, the population mean difference (<span class="math inline">\(\mu_d\)</span>) is calculated by taking the mean of all the differences between pairs in the population. This is done by subtracting the second value in each pair from the first value in each pair and then taking the mean of all the differences. <span class="math display">\[
\mu_d = \frac{1}{N} \sum_{i=1}^{N} d_i \;\;\;\text{where}\;\; d_i = X_{2i} - X_{1i}
\]</span></p>
<p>Where <span class="math inline">\(d_i\)</span> is the list of differences between pairs for the whole population and <span class="math inline">\(N\)</span> is the number of pairs in the population.</p>
<p><strong>Set of Hypotheses:</strong> For a paired-samples z-test, the null hypothesis (<span class="math inline">\(H_0\)</span>) is that the population mean difference (<span class="math inline">\(\mu_d\)</span>) is equal to <span class="math inline">\(\delta_0\)</span>, usually 0. The alternative hypothesis (<span class="math inline">\(H_a\)</span>) is that the population mean difference is not equal to <span class="math inline">\(\delta_0\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
H_0: \mu_d = \delta_0\\
H_a: \mu_d \neq \delta_0
\end{align*}
\]</span></p>
<p><strong>Significance Level:</strong></p>
<p>The significance level (<span class="math inline">\(\alpha\)</span>) is the probability of rejecting the null hypothesis when it is true. We will use the most commonly used significance level, 0.05.</p>
<p><span class="math display">\[
\alpha = 0.05
\]</span></p>
<p><strong>Making the Sampling Distribution</strong></p>
<p>Imagine we took a million samples of pairs from the population. Each sample of pairs would have a slightly different mean difference. This is the sampling distribution for a paired test. This is useful since we can use the sampling distribution to calculate the probability of obtaining a sample mean difference as extreme or more extreme than what we would expect. Since sampling a population a million times is not feasible, we can use the <strong>Central Limit Theorem</strong> to create a sampling distribution of the mean difference. The Central Limit Theorem states that the sampling distribution of the mean difference will be normally distributed with a mean equal to the population mean difference and a standard deviation equal to the population standard deviation of the differences divided by the square root of the number of pairs. Thus the standard deviation of the sampling distribution of <span class="math inline">\(\bar{d}\)</span> would be equal to <span class="math inline">\(\sigma_{\bar{d}}\)</span></p>
<p><span class="math display">\[
\sigma_{\bar{d}} = \frac{\sigma_d}{\sqrt{n}}
\]</span></p>
<p>Under the null hypothesis, the sampling distribution of the mean difference would be centered at <span class="math inline">\(\delta_0\)</span>, rather than the actual population mean difference, <span class="math inline">\(\mu_d\)</span>. We do this because we are assuming that the null hypothesis is true. This is useful because we can see if it is probable that our sample would have come from a population with a mean difference equal to <span class="math inline">\(\delta_0\)</span> - meaning if our sample mean difference is significantly different from <span class="math inline">\(\delta_0\)</span>, we have found something interesting.</p>
<p>To clarify, this <strong>null distribution</strong> is what the distribution of test statistics would look like if the null hypothesis were true. The null distribution is a normal distribution with a mean equal to <span class="math inline">\(\delta_0\)</span> and a standard deviation equal to <span class="math inline">\(\sigma_{\bar{d}}\)</span>.</p>
<p><img src="images/delta0s.png" class="img-fluid"></p>
<p><strong>Our Sample</strong></p>
<p>The sample mean difference (<span class="math inline">\(\bar{d}\)</span>) is the average of all the differences (<span class="math inline">\(d_i\)</span>’s) in the sample that we collected. It is calculated by summing up all the differences in the sample and dividing by the number of pairs (<span class="math inline">\(n\)</span>).</p>
<p><span class="math display">\[
\bar{d} = \frac{\sum_{i=1}^{n}{d_i}}{n} \;\;\;\text{where}\;\; d_i = X_{2i} - X_{1i}
\]</span></p>
<p><em>Our Sample’s Test-Statistic:</em></p>
<p>We have just calculated the sample mean difference, <span class="math inline">\(\bar{d}\)</span>. We hypothesized that the population mean difference is equal to a <span class="math inline">\(\delta_0\)</span>. Since want to know if the sample mean difference is significantly different from <span class="math inline">\(\delta_0\)</span>, we can calculate our test-statistic, the z-score, to find out where on the sampling distribution our sample mean difference lies. The z-score is calculated using the sample mean difference, the population mean difference (<span class="math inline">\(\delta_0\)</span>), and the population standard deviation of differences.</p>
<p><span class="math display">\[
z = \frac{\bar{d}-\delta_0}{\sigma_{\bar{d}}}
\]</span></p>
<p><strong>Calculating the p-value</strong> In the context of a z-test, we use a standard normal distribution to derive a p-value. We begin by standardizing our findings (the sample mean difference) to our z-score test statistic using the population mean difference (<span class="math inline">\(\delta_0\)</span>), and the population standard deviation of differences. This z-score can then be used to find the p-value of our test.</p>
<p>Let <span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span> be a standard normal random variable and <span class="math inline">\(z\)</span> be the observed z-score.</p>
<p>Given this observed z-score, we can then compute the p-value, which is the probability of observing a z-score as extreme as <span class="math inline">\(z\)</span> under the null hypothesis.</p>
<ul>
<li><p>For a two-tailed z-test (where we’re testing for a difference in either direction): When <span class="math inline">\(H_a: \mu_d \neq \delta_0\)</span>, then <span class="math inline">\(p = 2 \times (1 - \text{Pr}(Z \leq |z|))\)</span></p></li>
<li><p>For a right-tailed z-test (where we’re testing for a difference in the positive direction): When <span class="math inline">\(H_a: \mu_d &gt; \delta_0\)</span>, then <span class="math inline">\(p = 1 - \text{Pr}(Z \leq z)\)</span></p></li>
<li><p>For a left-tailed z-test (where we’re testing for a difference in the negative direction): When <span class="math inline">\(H_a: \mu_d &lt; \delta_0\)</span>, then <span class="math inline">\(p = \text{Pr}(Z \leq z)\)</span></p></li>
</ul>
<p><em>Applet to calculate the p-value</em></p>
<center>
<div width="90%">
<iframe src="https://byuimath.com/apps/normprob.html?width=600&amp;z=1&amp;height=400&amp;left=1&amp;mid=0&amp;right=1&amp;area=a&amp;static=0&amp;title=1&amp;border=0" frameborder="0" width="650" height="450" data-external="1"></iframe>
</div>
</center>
</section>
<section id="independent-samples-test" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="independent-samples-test"><span class="header-section-number">3.3.3</span> Independent-Samples Test</h3>
<p>An independent-samples z-test, also known as a two-sample z-test, is used to compare the means of two independent groups to assess whether there is a statistically significant difference between the two population means. This test assumes both populations are normally distributed, and the <strong>population standard deviations are known</strong>.</p>
<p>Each group has its own population standard deviation:</p>
<p><span class="math display">\[
\sigma_1 = \text{known population standard deviation of group 1}
\]</span> <span class="math display">\[
\sigma_2 = \text{known population standard deviation of group 2}
\]</span></p>
<p><strong>Set of Hypotheses:</strong> For an independent-samples z-test, the null hypothesis (<span class="math inline">\(H_0\)</span>) is that the difference between the population means (<span class="math inline">\(\mu_1 - \mu_2\)</span>) is equal to a specified value, usually zero. The alternative hypothesis (<span class="math inline">\(H_a\)</span>) is that the difference between the population means is not equal to this specified value.</p>
<p><span class="math display">\[
\begin{align*}
H_0: \mu_1 - \mu_2 = \delta_0\\ \;\;\;\;\;\;
H_a: \mu_1 - \mu_2 \neq \delta_0
\end{align*}
\]</span></p>
<p><strong>Significance Level:</strong></p>
<p>The significance level (<span class="math inline">\(\alpha\)</span>) is the probability of rejecting the null hypothesis when it is true. We will use the most commonly used significance level, 0.05.</p>
<p><span class="math display">\[
\alpha = 0.05
\]</span></p>
<p><strong>Making the Sampling Distribution</strong></p>
<p>Similar to the tests above, if we took a million samples of two independent groups from the population, each sample would have a slightly different difference in means. This is the sampling distribution for an independent-samples test. This is useful since we can use the sampling distribution to calculate the probability of obtaining a difference in means as extreme or more extreme than what we would expect. Since sampling a population a million times is not feasible, we can use the <strong>Central Limit Theorem</strong> to create a sampling distribution of the difference in means. The Central Limit Theorem states that the sampling distribution of the difference in means will be normally distributed with a mean equal to the difference in population means and a standard deviation equal to the square root of the sum of the squares of the population standard deviations divided by the square root of the sample sizes. Thus the standard deviation of the sampling distribution of <span class="math inline">\(\bar{X_1} - \bar{X_2}\)</span> would be equal to <span class="math inline">\(\sigma_{\bar{X_1} - \bar{X_2}}\)</span></p>
<p>The standard error of the difference in sample means can be calculated from the population standard deviations of the two groups and the sizes of the two groups (<span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>). This is the standard deviation of the sampling distribution of the difference in sample means.</p>
<p><span class="math display">\[
\sigma_{\bar{X_1} - \bar{X_2}} = \sqrt{\left(\frac{\sigma_1^2}{n_1}\right) + \left(\frac{\sigma_2^2}{n_2}\right)}
\]</span></p>
<p><strong>Our Sample</strong></p>
<p>The sample means (<span class="math inline">\(\bar{X_1}\)</span> and <span class="math inline">\(\bar{X_2}\)</span>) are the averages of all the values in each group. They are calculated by summing up all the values in each group and dividing by the size of each group.</p>
<p><span class="math display">\[
\bar{X_1} = \frac{\sum_{i=1}^{n_1}{X_{1i}}}{n_1}
\]</span></p>
<p><span class="math display">\[
\bar{X_2} = \frac{\sum_{i=1}^{n_2}{X_{2i}}}{n_2}
\]</span></p>
<p><em>Our Sample’s Test-Statistic:</em></p>
<p>The test-statistic, the z-score, is calculated using the difference of the sample means, the hypothesized difference of the population means (which we’ve assumed to be <span class="math inline">\(\delta_0\)</span>), and the standard error.</p>
<p><span class="math display">\[
z = \frac{(\bar{X_1} - \bar{X_2}) - \delta_0}{\sigma_{\bar{X_1} - \bar{X_2}}}
\]</span></p>
<p><strong>Calculating the p-value</strong> In the context of two independent samples z-test, we use a standard normal distribution to derive a p-value. We begin by standardizing our test statistic (the difference in sample means) to a z-score using the hypothesized difference in population means and the standard error. This z-score can then be used to find the p-value of our test.</p>
<p>Let’s denote the z-score for this test as <span class="math inline">\(z\)</span> and standard normal random variable as <span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span>. The z-score is calculated considering the difference between sample means, the hypothesized difference (often zero), and the standard error of the difference between means. Once we have the calculated z-score, we can use it to find the p-value of our test. The p-value, similar to the one-sample case, is the probability of observing a z-score as extreme as <span class="math inline">\(z\)</span> under the null hypothesis, and its calculation depends on the alternative hypothesis:</p>
<ul>
<li>For a two-tailed z-test (where we’re testing for a difference in either direction): When <span class="math inline">\(H_a: \mu_1 \neq \mu_2\)</span>, then <span class="math inline">\(p = 2 \times (1 - \text{Pr}(Z \leq |z|))\)</span></li>
<li>For a right-tailed z-test (where we’re testing for a difference in the positive direction): When <span class="math inline">\(H_a: \mu_1 &gt; \mu_2\)</span>, then <span class="math inline">\(p = 1 - \text{Pr}(Z \leq z)\)</span></li>
<li>For a left-tailed z-test (where we’re testing for a difference in the negative direction): When <span class="math inline">\(H_a: \mu_1 &lt; \mu_2\)</span>, then <span class="math inline">\(p = \text{Pr}(Z \leq z)\)</span></li>
</ul>
<p><em>Applet to calculate the p-value</em></p>
<center>
<div width="90%">
<iframe src="https://byuimath.com/apps/normprob.html?width=600&amp;z=1&amp;height=400&amp;left=1&amp;mid=0&amp;right=1&amp;area=a&amp;static=0&amp;title=1&amp;border=0" frameborder="0" width="650" height="450" data-external="1"></iframe>
</div>
</center>
<p><strong>Cohen’s d Effect Size</strong></p>
<p>We often want to measure the size of the difference between our two groups, not just whether this difference is statistically significant. This is where effect size comes in.</p>
<p>For a two-sample z-test, we can calculate the effect size using Cohen’s d.&nbsp;It is defined as the difference between two means divided by a standard deviation for the data.</p>
<p><span class="math display">\[
d = \frac{(\bar{X_1} - \bar{X_2})}{\sqrt{\left(\frac{\sigma_1^2}{2}\right) + \left(\frac{\sigma_2^2}{2}\right)}}
\]</span></p>
<p>Cohen’s d is an appropriate effect size for the comparison between two means.</p>
</section>
</section>
<section id="t-tests" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="t-tests"><span class="header-section-number">3.4</span> t-tests</h2>
<section id="one-sample-test-2" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="one-sample-test-2"><span class="header-section-number">3.4.1</span> One-Sample Test</h3>
<p>A one-sample t-test is used to compare the mean of a sample to a specified value. It is a parametric test that assumes the population is normally distributed and that the <strong>population standard deviation is unknown</strong>. The test statistic for a one-sample t-test is the t-score, which is calculated using the sample mean, the specified value, and the sample standard deviation.</p>
<p><strong>Set of Hypotheses:</strong> For a one-sample t-test, the null hypothesis (<span class="math inline">\(H_0\)</span>) is that the population mean (<span class="math inline">\(\mu\)</span>) is equal to a specified value (<span class="math inline">\(\mu_0\)</span>). The alternative hypothesis (<span class="math inline">\(H_a\)</span>) is that the population mean (<span class="math inline">\(\mu\)</span>) is not equal to the specified value (<span class="math inline">\(\mu_0\)</span>).</p>
<p><span class="math display">\[
\begin{align*}
H_0: \mu = \mu_0\\ \;\;\;\;\;
H_a: \mu \neq \mu_0
\end{align*}
\]</span></p>
<p><strong>Significance Level:</strong></p>
<p>The significance level (<span class="math inline">\(\alpha\)</span>) is the probability of rejecting the null hypothesis when it is true. We will use the most commonly used significance level, 0.05.</p>
<p><span class="math display">\[
\alpha = 0.05
\]</span></p>
<p><strong>Making the Sampling Distribution</strong></p>
<p>Just like with the z-test, we can imagine taking many samples from the population. Each sample would have a slightly different mean. These sample means would form a distribution, called the sampling distribution. Due to the <strong>Central Limit Theorem</strong>, the sampling distribution of the sample means will be approximately normally distributed, with a mean equal to the population mean and a standard error (SE) equal to the sample standard deviation divided by the square root of the sample size. Since we are estimating the normal distribution with the sample standard deviation, we use the t-distribution instead of the normal distribution to estimate the sampling distribution.</p>
<p><span class="math display">\[
s_{\bar{X}} = \frac{s}{\sqrt{n}}
\]</span></p>
<p>Under the null hypothesis, the sampling distribution of the mean would be centered at <span class="math inline">\(\mu_0\)</span>, rather than the actual population mean, <span class="math inline">\(\mu\)</span>. We do this because we are assuming that the null hypothesis is true. This is useful because we can see if it is probable that our sample would have come from a population with a mean equal to <span class="math inline">\(\mu_0\)</span>- meaning if our sample mean is significantly different from <span class="math inline">\(\mu_0\)</span>, we have found something interesting.</p>
<p>To clarify, this <strong>null distribution</strong> is what the distribution of test statistics would look like if the null hypothesis were true. The null distribution is a normal distribution with a mean equal to <span class="math inline">\(\mu_0\)</span> and a standard deviation equal to <span class="math inline">\(s_{\bar{X}}\)</span>. Since we are estimating the population standard deviation with the sample standard deviation, we use the t-distribution instead of the normal distribution to estimate the sampling distribution.</p>
<p><em>Below is a visualization of the hypothesized null distribution</em></p>
<p><img src="images/mu0s.png" class="img-fluid"></p>
<p><strong>Our Sample</strong></p>
<p>The sample mean (<span class="math inline">\(\bar{X}\)</span>) is the average of all the values (<span class="math inline">\(X_i\)</span>’s’) in the sample that we collected. It is calculated by summing up all the values in the sample and dividing by the sample size (<span class="math inline">\(n\)</span>).</p>
<p><span class="math display">\[
\bar{X} = \frac{\sum_{i=1}^{n}{X_i}}{n}
\]</span></p>
<p><em>Our Sample’s Test-Statistic:</em></p>
<p>We have just caluclated the sample mean, <span class="math inline">\(\bar{X}\)</span>. We hypothesized that the population mean is equal to a specified value, <span class="math inline">\(\mu_0\)</span>. We want to know if the sample mean is significantly different from the population mean. We can calculate our test-statistic, the t-value, to find out where on the sampling distribution our sample mean lies. The t-value is calculated using the sample mean, the population mean, and the sample standard deviation.</p>
<p><span class="math display">\[
t = \frac{\bar{X} - \mu_0}{s_{\bar{X}}}
\]</span></p>
<p><strong>Calculating the p-value</strong> In the context of a one-sample t-test, we use a t-distribution to derive a p-value. We begin by standardizing our test statistic (the sample mean) to a t-score using the hypothesized population mean and the sample standard deviation. This t-score can then be used to find the p-value of our test.</p>
<p>Let <span class="math inline">\(T \sim \mathcal{t}_{(n-1)}\)</span> be a t-distributed random variable with <span class="math inline">\(n-1\)</span> degrees of freedom and <span class="math inline">\(t\)</span> be the observed t-score. Given this observed t-score, we can then compute the p-value, which is the probability of observing a t-score as extreme as <span class="math inline">\(t\)</span> under the null hypothesis.</p>
<ul>
<li>For a two-tailed t-test (where we’re testing for a difference in either direction): When <span class="math inline">\(H_a: \mu \neq \mu_0\)</span>, then <span class="math inline">\(p = 2 \times (1 - \text{Pr}(T \leq |t|))\)</span></li>
<li>For a right-tailed t-test (where we’re testing for a difference in the positive direction): When <span class="math inline">\(H_a: \mu &gt; \mu_0\)</span>, then <span class="math inline">\(p = 1 - \text{Pr}(T \leq t)\)</span></li>
<li>For a left-tailed t-test (where we’re testing for a difference in the negative direction): When <span class="math inline">\(H_a: \mu &lt; \mu_0\)</span>, then <span class="math inline">\(p = \text{Pr}(T \leq t)\)</span></li>
</ul>
<p><em>Applet to calculate the p-value</em></p>
<center>
<div width="90%">
<iframe src="https://byuimath.com/apps/normprobwitht.html?width=600&amp;z=1&amp;height=400&amp;left=1&amp;mid=0&amp;right=1&amp;area=a&amp;static=0&amp;title=1&amp;border=0" frameborder="0" width="650" height="450" data-external="1"></iframe>
</div>
</center>
</section>
<section id="paired-samples-test-1" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="paired-samples-test-1"><span class="header-section-number">3.4.2</span> Paired-Samples Test</h3>
<p>A paired-samples t-test, also known as a dependent sample t-test, is used to compare the mean differences of two related groups to assess whether the mean difference between paired observations in the population is significantly different from a number (usually zero). This test assumes the differences between pairs are normally distributed and the <strong>population standard deviation of the differences is unknown</strong>. The test statistic for a paired-samples t-test is the t-value, which is calculated using the sample mean difference, the population mean difference, and the population standard deviation of the differences.</p>
<p>Additionally, the population mean difference (<span class="math inline">\(\mu_d\)</span>) is calculated by taking the mean of all the differences between pairs in the population. This is done by subtracting the second value in each pair from the first value in each pair and then taking the mean of all the differences. <span class="math display">\[
\mu_d = \frac{1}{N} \sum_{i=1}^{N} d_i \;\;\;\text{where}\;\; d_i = X_{2i} - X_{1i}
\]</span></p>
<p>Where <span class="math inline">\(d_i\)</span> is the list of differences between pairs for the whole population and <span class="math inline">\(N\)</span> is the number of pairs in the population.</p>
<p><strong>Set of Hypotheses:</strong> For a paired-samples t-test, the null hypothesis (<span class="math inline">\(H_0\)</span>) is that the population mean difference (<span class="math inline">\(\mu_d\)</span>) is equal to <span class="math inline">\(\delta_0\)</span>, usually 0. The alternative hypothesis (<span class="math inline">\(H_a\)</span>) is that the population mean difference is not equal to <span class="math inline">\(\delta_0\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
H_0: \mu_d = \delta_0\\
H_a: \mu_d \neq \delta_0
\end{align*}
\]</span></p>
<p><strong>Significance Level:</strong></p>
<p>The significance level (<span class="math inline">\(\alpha\)</span>) is the probability of rejecting the null hypothesis when it is true. We will use the most commonly used significance level, 0.05.</p>
<p><span class="math display">\[
\alpha = 0.05
\]</span></p>
<p><strong>Making the Sampling Distribution</strong></p>
<p>Imagine we took a million samples of pairs from the population. Each sample of pairs would have a slightly different mean difference. This is the sampling distribution for a paired test. This is useful since we can use the sampling distribution to calculate the probability of obtaining a sample mean difference as extreme or more extreme than what we would expect. Since sampling a population a million times is not feasible, we can use the <strong>Central Limit Theorem</strong> to create a sampling distribution of the mean difference. The Central Limit Theorem states that the sampling distribution of the mean difference will be normally distributed with a mean equal to the population mean difference and a standard deviation equal to the population standard deviation of the differences divided by the square root of the number of pairs. Thus the standard deviation of the sampling distribution of <span class="math inline">\(\bar{d}\)</span> would be equal to <span class="math inline">\(s_{\bar{d}}\)</span></p>
<p><span class="math display">\[
s_{\bar{d}} = \frac{s_d}{\sqrt{n}}
\]</span></p>
<p>Under the null hypothesis, the sampling distribution of the mean difference would be centered at <span class="math inline">\(\delta_0\)</span>, rather than the actual population mean difference, <span class="math inline">\(\mu_d\)</span>. We do this because we are assuming that the null hypothesis is true. This is useful because we can see if it is probable that our sample would have come from a population with a mean difference equal to <span class="math inline">\(\delta_0\)</span> - meaning if our sample mean difference is significantly different from <span class="math inline">\(\delta_0\)</span>, we have found something interesting.</p>
<p>To clarify, this <strong>null distribution</strong> is what the distribution of test statistics would look like if the null hypothesis were true. The null distribution is a normal distribution with a mean equal to <span class="math inline">\(\delta_0\)</span> and a standard deviation equal to <span class="math inline">\(s_{\bar{d}}\)</span>. Since we are estimating the population standard deviation with the sample standard deviation, we use the t-distribution instead of the normal distribution to estimate the sampling distribution.</p>
<p><img src="images/delta0s.png" class="img-fluid"></p>
<p><strong>Our Sample</strong></p>
<p>The sample mean difference (<span class="math inline">\(\bar{d}\)</span>) is the average of all the differences (<span class="math inline">\(d_i\)</span>’s) in the sample that we collected. It is calculated by summing up all the differences in the sample and dividing by the number of pairs (<span class="math inline">\(n\)</span>).</p>
<p><span class="math display">\[
\bar{d} = \frac{\sum_{i=1}^{n}{d_i}}{n} \;\;\;\text{where}\;\; d_i = X_{2i} - X_{1i}
\]</span></p>
<p><em>Our Sample’s Test-Statistic:</em></p>
<p>We have just calculated the sample mean difference, <span class="math inline">\(\bar{d}\)</span>. We hypothesized that the population mean difference is equal to a <span class="math inline">\(\delta_0\)</span>. Since want to know if the sample mean difference is significantly different from <span class="math inline">\(\delta_0\)</span>, we can calculate our test-statistic, the t-value, to find out where on the sampling distribution our sample mean difference lies. The t-value is calculated using the sample mean difference, the population mean difference (<span class="math inline">\(\delta_0\)</span>), and the population standard deviation of differences.</p>
<p><span class="math display">\[
t = \frac{\bar{d}-\delta_0}{s_{\bar{d}}}
\]</span></p>
<p><strong>Calculating the p-value</strong> In the context of a t-test, we use a standard normal distribution to derive a p-value. We begin by standardizing our findings (the sample mean difference) to our t-value test statistic using the population mean difference (<span class="math inline">\(\delta_0\)</span>), and the population standard deviation of differences. This t-value can then be used to find the p-value of our test.</p>
<p>Let <span class="math inline">\(T \sim \mathcal{t}_{(n-1)}\)</span> be a t-distributed random variable with <span class="math inline">\(n-1\)</span> degrees of freedom and <span class="math inline">\(t\)</span> be the observed t-score. Given this observed t-score, we can then compute the p-value, which is the probability of observing a t-score as extreme as <span class="math inline">\(t\)</span> under the null hypothesis.</p>
<ul>
<li><p>For a two-tailed t-test (where we’re testing for a difference in either direction): When <span class="math inline">\(H_a: \mu_d \neq \delta_0\)</span>, then <span class="math inline">\(p = 2 \times (1 - \text{Pr}(T \leq |t|))\)</span></p></li>
<li><p>For a right-tailed t-test (where we’re testing for a difference in the positive direction): When <span class="math inline">\(H_a: \mu_d &gt; \delta_0\)</span>, then <span class="math inline">\(p = 1 - \text{Pr}(T \leq t)\)</span></p></li>
<li><p>For a left-tailed t-test (where we’re testing for a difference in the negative direction): When <span class="math inline">\(H_a: \mu_d &lt; \delta_0\)</span>, then <span class="math inline">\(p = \text{Pr}(T \leq t)\)</span></p></li>
</ul>
<p><em>Applet to calculate the p-value</em></p>
<center>
<div width="90%">
<iframe src="https://byuimath.com/apps/normprobwitht.html?width=600&amp;z=1&amp;height=400&amp;left=1&amp;mid=0&amp;right=1&amp;area=a&amp;static=0&amp;title=1&amp;border=0" frameborder="0" width="650" height="450" data-external="1"></iframe>
</div>
</center>
</section>
<section id="independent-samples-test-1" class="level3" data-number="3.4.3">
<h3 data-number="3.4.3" class="anchored" data-anchor-id="independent-samples-test-1"><span class="header-section-number">3.4.3</span> Independent-Samples Test</h3>
<p>An independent-samples t-test, also known as a two-sample t-test, is used to compare the means of two independent groups to assess whether there is a statistically significant difference between the two population means. This test assumes both populations are normally distributed, and the <strong>population standard deviations are unknown</strong>.</p>
<p>Each group has its own population standard deviation:</p>
<p><strong>Set of Hypotheses:</strong> For an independent-samples t-test, the null hypothesis (<span class="math inline">\(H_0\)</span>) is that the difference between the population means (<span class="math inline">\(\mu_1 - \mu_2\)</span>) is equal to a specified value, usually zero. The alternative hypothesis (<span class="math inline">\(H_a\)</span>) is that the difference between the population means is not equal to this specified value.</p>
<p><span class="math display">\[
\begin{align*}
H_0: \mu_1 - \mu_2 = \delta_0\\ \;\;\;\;\;\;
H_a: \mu_1 - \mu_2 \neq \delta_0
\end{align*}
\]</span></p>
<p><strong>Significance Level:</strong></p>
<p>The significance level (<span class="math inline">\(\alpha\)</span>) is the probability of rejecting the null hypothesis when it is true. We will use the most commonly used significance level, 0.05.</p>
<p><span class="math display">\[
\alpha = 0.05
\]</span></p>
<p><strong>Making the Sampling Distribution</strong></p>
<p>Similar to the tests above, if we took a million samples of two independent groups from the population, each sample would have a slightly different difference in means. This is the sampling distribution for an independent-samples test. This is useful since we can use the sampling distribution to calculate the probability of obtaining a difference in means as extreme or more extreme than what we would expect. Since sampling a population a million times is not feasible, we can use the <strong>Central Limit Theorem</strong> to create a sampling distribution of the difference in means. The Central Limit Theorem states that the sampling distribution of the difference in means will be normally distributed with a mean equal to the difference in population means and a standard deviation equal to the square root of the sum of the squares of the population standard deviations divided by the square root of the sample sizes. Thus the standard deviation of the sampling distribution of <span class="math inline">\(\bar{X_1} - \bar{X_2}\)</span> would be equal to <span class="math inline">\(s_{\bar{X_1} - \bar{X_2}}\)</span></p>
<p>The standard error of the difference in sample means can be calculated from the population standard deviations of the two groups and the sizes of the two groups (<span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span>). This is the standard deviation of the sampling distribution of the difference in sample means.</p>
<p><span class="math display">\[
s_{\bar{X_1} - \bar{X_2}} = \sqrt{\left(\frac{s_1^2}{n_1}\right) + \left(\frac{s_2^2}{n_2}\right)}
\]</span></p>
<p><strong>Our Sample</strong></p>
<p>The sample means (<span class="math inline">\(\bar{X_1}\)</span> and <span class="math inline">\(\bar{X_2}\)</span>) are the averages of all the values in each group. They are calculated by summing up all the values in each group and dividing by the size of each group.</p>
<p><span class="math display">\[
\bar{X_1} = \frac{\sum_{i=1}^{n_1}{X_{1i}}}{n_1}
\]</span></p>
<p><span class="math display">\[
\bar{X_2} = \frac{\sum_{i=1}^{n_2}{X_{2i}}}{n_2}
\]</span></p>
<p><em>Our Sample’s Test-Statistic:</em></p>
<p>The test-statistic, the t-value, is calculated using the difference of the sample means, the hypothesized difference of the population means (which we’ve assumed to be <span class="math inline">\(\delta_0\)</span>), and the standard error.</p>
<p><span class="math display">\[
t = \frac{(\bar{X_1} - \bar{X_2}) - \delta_0}{s_{\bar{X_2} - \bar{X_1}}}
\]</span></p>
<p><strong>Calculating the p-value</strong> For two independent samples t-test, we use a t-distribution to derive a p-value. We begin by standardizing our test statistic (the difference in sample means) to a t-score using the hypothesized difference in population means and the standard error. This t-score can then be used to find the p-value of our test.</p>
<p>Let’s denote the t-score for this test as <span class="math inline">\(t\)</span> and a t-distributed random variable with <span class="math inline">\(n_1 + n_2 - 2\)</span> degrees of freedom as <span class="math inline">\(T \sim \mathcal{t}_{(n_1 + n_2 - 2)}\)</span>. The t-score is calculated considering the difference between sample means, the hypothesized difference (often zero), and the standard error of the difference between means. Once we have the calculated t-score, we can use it to find the p-value of our test. The p-value is the probability of observing a t-score as extreme as <span class="math inline">\(t\)</span> under the null hypothesis, and its calculation depends on the alternative hypothesis:</p>
<ul>
<li>For a two-tailed t-test (where we’re testing for a difference in either direction): When <span class="math inline">\(H_a: \mu_1 \neq \mu_2\)</span>, then <span class="math inline">\(p = 2 \times (1 - \text{Pr}(T \leq |t|))\)</span></li>
<li>For a right-tailed t-test (where we’re testing for a difference in the positive direction): When <span class="math inline">\(H_a: \mu_1 &gt; \mu_2\)</span>, then <span class="math inline">\(p = 1 - \text{Pr}(T \leq t)\)</span></li>
<li>For a left-tailed t-test (where we’re testing for a difference in the negative direction): When <span class="math inline">\(H_a: \mu_1 &lt; \mu_2\)</span>, then <span class="math inline">\(p = \text{Pr}(T \leq t)\)</span></li>
</ul>
<p>Just like the z-test, we compare the calculated p-value with our significance level to decide whether to reject or not reject the null hypothesis. If the p-value is less than the chosen significance level (often 0.05), then we reject the null hypothesis in favor of the alternative hypothesis. If the p-value is greater than the significance level, we do not reject the null hypothesis.</p>
<p><em>Applet to calculate the p-value</em></p>
<center>
<div width="90%">
<iframe src="https://byuimath.com/apps/normprobwitht.html?width=600&amp;z=1&amp;height=400&amp;left=1&amp;mid=0&amp;right=1&amp;area=a&amp;static=0&amp;title=1&amp;border=0" frameborder="0" width="650" height="450" data-external="1"></iframe>
</div>
</center>
<p><strong>Cohen’s d Effect Size</strong></p>
<p>We often want to measure the size of the difference between our two groups, not just whether this difference is statistically significant. This is where effect size comes in.</p>
<p>For a two-sample t-test, we can calculate the effect size using Cohen’s d.&nbsp;It is defined as the difference between two means divided by a standard deviation for the data.</p>
<p><span class="math display">\[
d = \frac{(\bar{X_1} - \bar{X_2})}{\sqrt{\left(\frac{s_1^2}{2}\right) + \left(\frac{s_2^2}{2}\right)}}
\]</span></p>
<p>Cohen’s d is an appropriate effect size for the comparison between two means.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./i_distributions.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Univariate Distributions</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./i_bivariate.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bivariate Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>